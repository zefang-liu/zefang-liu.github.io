---
title: "SecQA: A Concise Question-Answering Dataset for Evaluating Large Language Models in Computer Security"
authors: "<b>Zefang Liu</b>"
collection: publications
category: conferences
permalink: /publication/liu2023secqa
excerpt: 'SecQA introduces a specialized dataset for evaluating the performance of large language models in computer security through multiple-choice questions.'
date: 2023-12-01
venue: 'arXiv preprint arXiv:2312.15838'
paperurl: 'https://arxiv.org/abs/2312.15838'
codeurl: 'https://github.com/zefang-liu/lm-evaluation-harness'
dataurl: 'https://huggingface.co/datasets/zefang-liu/secqa'
citation: 'Liu, Zefang. &quot;SecQA: A Concise Question-Answering Dataset for Evaluating Large Language Models in Computer Security.&quot; <i>arXiv preprint arXiv:2312.15838</i> (2023).'
---

**Abstract**

In this paper, we introduce SecQA, a novel dataset tailored for evaluating the performance of Large Language Models (LLMs) in the domain of computer security. Utilizing multiple-choice questions generated by GPT-4 based on the "Computer Systems Security: Planning for Success" textbook, SecQA aims to assess LLMs' understanding and application of security principles. We detail the structure and intent of SecQA, which includes two versions of increasing complexity, to provide a concise evaluation across various difficulty levels. Additionally, we present an extensive evaluation of prominent LLMs, including GPT-3.5-Turbo, GPT-4, Llama-2, Vicuna, Mistral, and Zephyr models, using both 0-shot and 5-shot learning settings. Our results, encapsulated in the SecQA v1 and v2 datasets, highlight the varying capabilities and limitations of these models in the computer security context. This study not only offers insights into the current state of LLMs in understanding security-related content but also establishes SecQA as a benchmark for future advancements in this critical research area.
